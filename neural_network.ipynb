{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy.special #シグモイド関数expit()使用のため\n",
    "\n",
    "# ニューラルネットワーククラスの定義\n",
    "class neuralNetwork:\n",
    "    \n",
    "    # ニューラルネットワークの初期化\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # 入力層　隠れ層　出力層のノード数の設定\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "    # リンクの重み3*3の行列を作る \n",
    "    #input-hiddenのweight（wih）　と　hidden-outputのweight（who）の２種類\n",
    "        # 行列内の重み weight_ノードi_ノードjへのリンクの重み\n",
    "        # 重みの値は、0.0を平均としてリンクの数の平方根の逆数の範囲にする。pow(self.hnodes, -0.5)はself.hnodesを-1/2乗(power)している（つまり平方根の逆数を取る計算）\n",
    "        # numpy.random.normal（loc（平均） = 0.0、scale（範囲） = 1.0、size = None(例えば(2,3)なら2行3列の行列を作る) ）\n",
    "        # w11 w21\n",
    "        # w12 w22　など\n",
    "        self.wih = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.normal(0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes))\n",
    "        \n",
    "    # 学習率の設定\n",
    "        self.lr = learningrate\n",
    "        \n",
    "    # 活性化関数（シグモイド関数）の定義\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "      \n",
    "    \n",
    "        pass\n",
    "    \n",
    "    # ニューラルネットワークの学習\n",
    "    def train():\n",
    "        \n",
    "    #---------------------------------入力値と出力値の計算--------------------------------------------------------------\n",
    "        # 入力リストを行列に変換（.Tは.transpose()と一緒で転置行列を表す）\n",
    "            #入力は横並びのリストに入れるので、それを縦に並べる処理\n",
    "            # 例：\n",
    "            # input=>  a = ([1.0, 0.5, -1.5])\n",
    "            # input=>  b = numpy.array(a, ndmin=2).T\n",
    "            # input=>  b\n",
    "            # output=>  array([[ 1. ],\n",
    "            # output=>     [ 0.5],\n",
    "            # output=>     [-1.5]])\n",
    "        \n",
    "            # numpy.array(object, dtype=None, copy=True, order='K', subok=False, ndmin=0)\n",
    "            # ndminは結果の配列に必要な最小次元数を指定します。この要件を満たすために、必要に応じて形状にあらかじめペンディングされます。\n",
    "       \n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T    #targetsは目標出力\n",
    "        \n",
    "        \n",
    "        #　隠れ層に入ってくる信号の計算\n",
    "        # 重みとinputの行列を計算して出力値をだす\n",
    "          #numpy.dot(a, b, out = None)\n",
    "          # aは左からかける行列　bは右からかける行列\n",
    "        hidden_inputs = numpy.dot(self.wih,inputs)\n",
    "        \n",
    "        \n",
    "        # 隠れ層で結合された信号を活性化関数により出力\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "\n",
    "        #　出力層に入ってくる信号の計算\n",
    "        final_inputs = numpy.dot(self.who,hidden_outputs)\n",
    "        # 出力層で結合された信号を活性化関数により出力\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "\n",
    "    #---------------------------------誤差逆伝播の計算--------------------------------------------------------------\n",
    "        #目標出力(targets) と最終出力(final_outputs)の差分を計算して出力層の誤差を求め、それを使って転置行列をかけると隠れ層の誤差が更新される。\n",
    "        \n",
    "        #出力層の誤差 = (目標出力(targets) - 最終出力(final_outputs)) \n",
    "        output_errors = targets - final_outputs\n",
    "        #隠れ層の誤差は出力層の誤差をリンクの重みの割合で更新（転置行列をかける）\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors)\n",
    "        \n",
    "    #---------------------------------重みの更新の計算--------------------------------------------------------------\n",
    "        \n",
    "        #上で誤差が更新されたら、その誤差を使って重みを更新する\n",
    "    \n",
    "        #隠れ層と出力層の間のリンクの重みを更新\n",
    "        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs))\n",
    "        #入力層と隠れ層の間のリンクの重みを更新\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))\n",
    "    \n",
    "        pass\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ニューラルネットワークへの照会\n",
    "    def query(self, inputs_list):\n",
    "        \n",
    "        # 入力リストを行列に変換\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        #　隠れ層に入ってくる信号の計算\n",
    "        hidden_inputs = numpy.dot(self.wih,inputs)\n",
    "        # 隠れ層で結合された信号を活性化関数により出力\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "\n",
    "        #　出力層に入ってくる信号の計算\n",
    "        final_inputs = numpy.dot(self.who,hidden_outputs)\n",
    "        # 出力層で結合された信号を活性化関数により出力\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "\n",
    "        return final_outputs\n",
    "        \n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#入力層　隠れ層　出力層のノード数\n",
    "input_nodes = 3\n",
    "hidden_nodes = 3\n",
    "output_nodes = 3\n",
    "\n",
    "#学習率\n",
    "learning_rate = 0.3\n",
    "\n",
    "#ニューラルネットワークのインスタンスの生成\n",
    "n = neuralNetwork(input_nodes,hidden_nodes,output_nodes,learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.51847515],\n",
       "         [0.53036463],\n",
       "         [0.50477237]],\n",
       "\n",
       "        [[0.48634541],\n",
       "         [0.45898627],\n",
       "         [0.48750689]],\n",
       "\n",
       "        [[0.642427  ],\n",
       "         [0.65546626],\n",
       "         [0.62579906]]],\n",
       "\n",
       "\n",
       "       [[[0.42716665],\n",
       "         [0.40661002],\n",
       "         [0.43067547]],\n",
       "\n",
       "        [[0.50514499],\n",
       "         [0.50603243],\n",
       "         [0.51767107]],\n",
       "\n",
       "        [[0.56103502],\n",
       "         [0.55760649],\n",
       "         [0.55797455]]],\n",
       "\n",
       "\n",
       "       [[[0.5499579 ],\n",
       "         [0.53262906],\n",
       "         [0.54656234]],\n",
       "\n",
       "        [[0.52099927],\n",
       "         [0.52425007],\n",
       "         [0.52546036]],\n",
       "\n",
       "        [[0.45302839],\n",
       "         [0.47402455],\n",
       "         [0.46768764]]]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.query([1.0, 0.5, -1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
